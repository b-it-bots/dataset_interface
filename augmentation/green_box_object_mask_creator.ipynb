{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unwanted stuff needed to run cv2 in python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing bounding box generation from mask\n",
    "\n",
    "* Testing the quality of the noise removal filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob \n",
    "import numpy as np \n",
    "from imageio import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vec2D(object):\n",
    "    def __init__(self, x=None, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "class BoundingBox(object):\n",
    "    def __init__(self):\n",
    "        self.nonzero_rows = None\n",
    "        self.nonzero_cols = None\n",
    "        self.min_coords = Vec2D()\n",
    "        self.max_coords = Vec2D()\n",
    "\n",
    "def get_bb_from_mask(segmentation_mask: np.array) -> BoundingBox:\n",
    "    '''Returns a BoundingBox object with information extracted\n",
    "    from the given segmentation mask.\n",
    "\n",
    "    Keyword arguments:\n",
    "    segmentation_mask: np.array -- a 2D numpy array representing a grayscale image\n",
    "                                   with a single object in it, where the assumption\n",
    "                                   is that non-zero pixels represent the object\n",
    "\n",
    "    '''\n",
    "    bb = BoundingBox()\n",
    "    bb.nonzero_rows, bb.nonzero_cols  = np.where(segmentation_mask)\n",
    "    bb.min_coords.x, bb.max_coords.x = (np.min(bb.nonzero_cols), np.max(bb.nonzero_cols))\n",
    "    bb.min_coords.y, bb.max_coords.y = (np.min(bb.nonzero_rows), np.max(bb.nonzero_rows))\n",
    "    return bb\n",
    "\n",
    "def get_bb(coords):\n",
    "    bb = BoundingBox()\n",
    "    bb.min_coords.x, bb.max_coords.x = (np.min(coords[0]), np.max(coords[0]))\n",
    "    bb.min_coords.y, bb.max_coords.y = (np.min(coords[1]), np.max(coords[1]))\n",
    "    return bb\n",
    "\n",
    "def generate_transformation(bb: BoundingBox, boundaries: tuple) -> np.array:\n",
    "    '''Generates a homogeneous transformation matrix of type int that translates,\n",
    "    rotates, and scales the given bounding box, ensuring that the\n",
    "    transformed points are within the given boundaries.\n",
    "\n",
    "    Keyword arguments:\n",
    "    bb: BoundingBox -- a BoundingBox object\n",
    "    boundaries: tuple -- coordinate boundaries; assumed to represent\n",
    "                         the (row, column) sizes of an image\n",
    "\n",
    "    '''\n",
    "    use_transformation = False\n",
    "    t = None\n",
    "    while not use_transformation:\n",
    "        use_transformation = True\n",
    "        rectangle_points = np.array([[bb.min_coords.x, bb.min_coords.x, bb.max_coords.x, bb.max_coords.x],\n",
    "                                     [bb.min_coords.y, bb.max_coords.y, bb.min_coords.y, bb.max_coords.y]])\n",
    "        rectangle_points = np.vstack((rectangle_points, [1., 1., 1., 1.]))\n",
    "\n",
    "        # we generate a random rotation angle\n",
    "        random_rot_angle = np.random.uniform(0, 2*np.pi)\n",
    "        random_rot_matrix = np.array([[np.cos(random_rot_angle), -np.sin(random_rot_angle)],\n",
    "                                      [np.sin(random_rot_angle), np.cos(random_rot_angle)]])\n",
    "\n",
    "        # we generate a random translation within the image boundaries\n",
    "        random_translation_x = np.random.uniform(-bb.min_coords.x, boundaries[1]-bb.max_coords.x)\n",
    "        random_translation_y = np.random.uniform(-bb.min_coords.y, boundaries[0]-bb.max_coords.y)\n",
    "        translation_vector = np.array([[random_translation_x], [random_translation_y]])\n",
    "\n",
    "        # we generate a random scaling factor between 0.5 and 1.5\n",
    "        # of the original object size\n",
    "        random_scaling_factor = np.random.uniform(0.5, 1.0)\n",
    "        s = np.array([[random_scaling_factor, 0., 0.],\n",
    "                      [0., random_scaling_factor, 0.],\n",
    "                      [0., 0., 1.]])\n",
    "\n",
    "        t = np.hstack((random_rot_matrix, translation_vector))\n",
    "        t = np.vstack((t, np.array([0., 0., 1.])))\n",
    "        t = t.dot(s)\n",
    "\n",
    "        transformed_bb = t.dot(rectangle_points)\n",
    "        transformed_bb = np.array(transformed_bb, dtype=int)\n",
    "        for point in transformed_bb.T:\n",
    "            if point[0] < 0 or point[0] >= boundaries[1] or \\\n",
    "               point[1] < 0 or point[1] >= boundaries[0]:\n",
    "                use_transformation = False\n",
    "                break\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n"
     ]
    }
   ],
   "source": [
    "# background_image_name = \"background_1_light_14/background_0.jpg\"\n",
    "# image_path = \"robocup_images/objects_perspectives/objects_front/food_container/yellow_bowl/yellow_bowl_0.jpg\"\n",
    "# segmentation_mask_path = \"robocup_images/objects_perspectives/objects_front/food_container/yellow_bowl/object_masks/yellow_bowl_0_mask.jpg\"\n",
    "\n",
    "num_image = 19\n",
    "\n",
    "image_path = \"robocup_objects/front/soap/stand_fa/stand_fa_{}.jpg\".format(num_image)\n",
    "segmentation_mask_path = \"robocup_objects/front/soap/stand_fa/object_masks/stand_fa_{}_mask.jpg\".format(num_image)\n",
    "\n",
    "# background_img = np.array(background_image_name, dtype=np.uint8)\n",
    "img = np.array(imread(image_path), dtype=np.uint8)\n",
    "\n",
    "# cv2.namedWindow(\"original\", cv2.WND_PROP_FULLSCREEN)\n",
    "# cv2.setWindowProperty(\"original\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# cv2.imshow('original', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# segmentation_mask = np.array(imread(segmentation_mask_path), dtype=np.uint8)\n",
    "\n",
    "segmentation_mask = cv2.imread(segmentation_mask_path, 0)\n",
    "print(segmentation_mask.shape)\n",
    "\n",
    "cv2.namedWindow(\"mask\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"mask\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('mask', segmentation_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "smoothed = cv2.GaussianBlur(segmentation_mask, (7,7),0)\n",
    "\n",
    "# smoothed = cv2.medianBlur(segmentation_mask, 7)\n",
    "\n",
    "opening = cv2.morphologyEx(smoothed,cv2.MORPH_OPEN,kernel, iterations = 10)\n",
    "\n",
    "cv2.namedWindow(\"opening\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"opening\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "                            \n",
    "\n",
    "# # sure background area\n",
    "# sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# cv2.imshow('Features', sure_bg)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Finding sure foreground area\n",
    "# dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "# ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# # Finding unknown region\n",
    "# sure_fg = np.uint8(sure_fg)\n",
    "# unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# cv2.imshow('Features', sure_fg)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "bb = get_bb_from_mask(opening)\n",
    "\n",
    "xmin = bb.min_coords.x\n",
    "xmax = bb.max_coords.x\n",
    "ymin = bb.min_coords.y\n",
    "ymax = bb.max_coords.y\n",
    "\n",
    "cv2.namedWindow(\"box\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"box\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
    "cv2.imshow('box', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the images in the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of backgrounds images  4\n",
      "Number of perspectives  2\n",
      "Number of classes  24\n",
      "robocup_images/objects_perspectives/objects_front/stapler\n",
      "robocup_images/objects_perspectives/objects_front/drinkware\n",
      "robocup_images/objects_perspectives/objects_front/pepper\n",
      "robocup_images/objects_perspectives/objects_front/tape\n",
      "robocup_images/objects_perspectives/objects_front/pringles\n",
      "robocup_images/objects_perspectives/objects_front/mr_muscle_box\n",
      "robocup_images/objects_perspectives/objects_front/cleaning_cloth\n",
      "robocup_images/objects_perspectives/objects_front/food_container\n",
      "robocup_images/objects_perspectives/objects_front/condensed_cream\n",
      "robocup_images/objects_perspectives/objects_front/dried_tomatoes\n",
      "robocup_images/objects_perspectives/objects_front/soapbar\n",
      "robocup_images/objects_perspectives/objects_front/cereal\n",
      "robocup_images/objects_perspectives/objects_front/sponge\n",
      "robocup_images/objects_perspectives/objects_front/toothpaste\n",
      "robocup_images/objects_perspectives/objects_front/toy\n",
      "robocup_images/objects_perspectives/objects_front/shampoo\n",
      "robocup_images/objects_perspectives/objects_front/tomato_paste\n",
      "robocup_images/objects_perspectives/objects_front/kitchen_utensil\n",
      "robocup_images/objects_perspectives/objects_front/cookies\n",
      "robocup_images/objects_perspectives/objects_front/noodle_box\n",
      "robocup_images/objects_perspectives/objects_front/nuts_mix\n",
      "robocup_images/objects_perspectives/objects_front/pasta\n",
      "robocup_images/objects_perspectives/objects_front/salt\n",
      "robocup_images/objects_perspectives/objects_front/drinks\n",
      "robocup_images/objects_perspectives/objects_top_down/stapler\n",
      "robocup_images/objects_perspectives/objects_top_down/drinkware\n",
      "robocup_images/objects_perspectives/objects_top_down/pepper\n",
      "robocup_images/objects_perspectives/objects_top_down/tape\n",
      "robocup_images/objects_perspectives/objects_top_down/pringles\n",
      "robocup_images/objects_perspectives/objects_top_down/mr_muscle_box\n",
      "robocup_images/objects_perspectives/objects_top_down/cleaning_cloth\n",
      "robocup_images/objects_perspectives/objects_top_down/food_container\n",
      "robocup_images/objects_perspectives/objects_top_down/condensed_cream\n",
      "robocup_images/objects_perspectives/objects_top_down/dried_tomatoes\n",
      "robocup_images/objects_perspectives/objects_top_down/soapbar\n",
      "robocup_images/objects_perspectives/objects_top_down/cereal\n",
      "robocup_images/objects_perspectives/objects_top_down/sponge\n",
      "robocup_images/objects_perspectives/objects_top_down/toothpaste\n",
      "robocup_images/objects_perspectives/objects_top_down/toy\n",
      "robocup_images/objects_perspectives/objects_top_down/shampoo\n",
      "robocup_images/objects_perspectives/objects_top_down/tomato_paste\n",
      "robocup_images/objects_perspectives/objects_top_down/kitchen_utensil\n",
      "robocup_images/objects_perspectives/objects_top_down/cookies\n",
      "robocup_images/objects_perspectives/objects_top_down/noodle_box\n",
      "robocup_images/objects_perspectives/objects_top_down/nuts_mix\n",
      "robocup_images/objects_perspectives/objects_top_down/pasta\n",
      "robocup_images/objects_perspectives/objects_top_down/salt\n",
      "robocup_images/objects_perspectives/objects_top_down/drinks\n"
     ]
    }
   ],
   "source": [
    "### Validating images taken as well as the segmentation masks\n",
    "\n",
    "background_img_dir = \"robocup_images/augmentation_backgrounds/\"\n",
    "img_dir_name = \"robocup_images/objects_perspectives/\"\n",
    "backgrounds = os.listdir(background_img_dir)\n",
    "print('Number of backgrounds images ', len(backgrounds))\n",
    "\n",
    "perspectives = os.listdir(img_dir_name)\n",
    "print('Number of perspectives ', len(perspectives))\n",
    "\n",
    "objects = os.listdir(os.path.join(img_dir_name,perspectives[0]))\n",
    "print('Number of classes ', len(objects))\n",
    "\n",
    "# # Generating images paths\n",
    "background_paths = []\n",
    "for background in backgrounds:\n",
    "    background_path = os.path.join(background_img_dir, background)\n",
    "    background_paths.append(background_path)\n",
    "\n",
    "objects_paths = []\n",
    "for perspective in perspectives:\n",
    "    for object in objects:\n",
    "        object_path = os.path.join(img_dir_name,perspective,object)\n",
    "        objects_paths.append(object_path)\n",
    "\n",
    "background_img = np.array(imread(background_paths[0]), dtype=np.uint8)\n",
    "\n",
    "for object_path in objects_paths:\n",
    "    print(object_path)\n",
    "    images = glob.glob(object_path+'/*.jpg')\n",
    "\n",
    "    if len(images) == 0:\n",
    "        # print('Inspecting subdirectories...')\n",
    "        images = glob.glob(object_path+'/**/*.jpg')\n",
    "#     print(len(images))\n",
    "    \n",
    "    for image_idx,_ in enumerate(images):\n",
    "        image_full_name = images[image_idx]\n",
    "#         print(\"\\t \", image_full_name)\n",
    "        img = np.array(imread(image_full_name), dtype=np.uint8)\n",
    "\n",
    "        # Obtain image name to find the mask\n",
    "        image_name = os.path.basename(image_full_name).split('.')[0]\n",
    "\n",
    "        # Obtain the path to the mask required\n",
    "        segmentation_dir = os.path.dirname(image_full_name)\n",
    "        segmentation_mask_path = os.path.join(segmentation_dir, 'object_masks',\n",
    "                                                      image_name + '_mask'+'.jpg')\n",
    "        \n",
    "        segmentation_mask = cv2.imread(segmentation_mask_path, 0)\n",
    "#         print(segmentation_mask_path)\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        smoothed = cv2.GaussianBlur(segmentation_mask, (7,7),0)\n",
    "        segmentation_mask = cv2.morphologyEx(smoothed,cv2.MORPH_OPEN,kernel, iterations = 10)\n",
    "        try:\n",
    "            bb = get_bb_from_mask(segmentation_mask)\n",
    "        except:\n",
    "            print(\"\\033[1;31mInvalid mask  \\n {} \\n {}\\033[0;37m\".format(image_full_name, segmentation_mask_path))\n",
    "            continue\n",
    "\n",
    "        t = generate_transformation(bb, background_img.shape)\n",
    "        # the object points are transformed with the given transformation matrix\n",
    "        obj_coords = np.vstack((bb.nonzero_cols[np.newaxis],\n",
    "                                bb.nonzero_rows[np.newaxis],\n",
    "                                np.ones(len(bb.nonzero_rows), dtype=int)))\n",
    "        transformed_obj_coords = t.dot(obj_coords)\n",
    "        transformed_obj_coords = np.array(transformed_obj_coords, dtype=int)\n",
    "        transformed_bb = get_bb(transformed_obj_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "# sys.path.remove('/home/kramer/Documents/ROS/catkin_ws/devel/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread, imwrite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "threshold = 80\n",
    "\n",
    "img = np.array(imread(\"robocup_images/objects_front/tableware/blue_plate/blue_plate_0.jpg\"), dtype=int)\n",
    "# img = np.array(imread(\"robocup_images/objects_front/cereal/chockn_roll/chockn_roll_0.jpg\"), dtype=int)\n",
    "background = np.array(imread(\"background_1_light_14/background_0.jpg\"), dtype=int)\n",
    "img_diff = np.clip(np.abs(img - background), 0, 255)\n",
    "img_diff = np.array(img_diff, dtype=np.uint8)\n",
    "\n",
    "small_brightness_pixels = np.where(img_diff < threshold)\n",
    "img_diff[small_brightness_pixels] = 0\n",
    "\n",
    "# high_brightness_pixels = np.where(img_diff > threshold)\n",
    "# img_diff[high_brightness_pixels] = 255\n",
    "\n",
    "\n",
    "fig = plt.figure(1, (20,8))\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(background)\n",
    "fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(img)\n",
    "fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(img_diff)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mask to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "im2 = cv2.cvtColor(img_diff,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(im2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate bounding box using mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_rows, nonzero_cols = np.where(im2)\n",
    "min_i, max_i = (np.min(nonzero_rows), np.max(nonzero_rows))\n",
    "min_j, max_j = (np.min(nonzero_cols), np.max(nonzero_cols))\n",
    "# indices = np.meshgrid(np.arange(np.min(i), np.max(i) + 1),\n",
    "#                       np.arange(np.min(j), np.max(j) + 1),\n",
    "#                       indexing='ij')\n",
    "plt.imshow(im2[min_i:max_i, min_j:max_j], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "cv2.rectangle(im2,(min_j,min_i),(max_j,max_i),(255,255,255),2)\n",
    "cv2.imshow('Features', im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate mask with bounding in artificial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_rows, nonzero_cols = np.where(im2)\n",
    "min_i, max_i = (np.min(nonzero_rows), np.max(nonzero_rows))\n",
    "min_j, max_j = (np.min(nonzero_cols), np.max(nonzero_cols))\n",
    "\n",
    "back_image = imread('robocup_images/augmentation_backgrounds/apartment.jpg')\n",
    "# obj_rectangle = np.where(im2[min_i:max_i, min_j:max_j] > 0)\n",
    "\n",
    "# back_image[i, j] = img[i, j]\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(back_image)\n",
    "# plt.show()\n",
    "# cv2.rectangle(back_image,(min_j,min_i),(max_j,max_i),(255,255,255),2)\n",
    "# cv2.imshow('Features', back_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from imageio import imread, imwrite\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('coords_train.csv', sep=',')\n",
    "df_val = pd.read_csv('coords_val.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml \n",
    "import os \n",
    "\n",
    "# img = cv2.imread('robocup_images/training_images/sponge_top_05_04_19_18_308.jpg')\n",
    "# img_name = 'validation_images/sponge_top_05_04_19_18_308.jpg'\n",
    "with open('robocup_images/train_annotations.yml', 'r') as annotations_f:\n",
    "    annotations = yaml.load(annotations_f, Loader=yaml.FullLoader)\n",
    "folder = 'robocup_images'\n",
    "for img_dict in annotations:\n",
    "#     if img_dict['image_name'] == img_name:\n",
    "    img_name = img_dict['image_name']\n",
    "    img_path = os.path.join(folder,img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    objects = img_dict['objects']\n",
    "    for object_ in objects:\n",
    "        xmin = object_['xmin']\n",
    "        xmax = object_['xmax']\n",
    "        ymin = object_['ymin']\n",
    "        ymax = object_['ymax']\n",
    "        cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
    "    cv2.imshow('Features', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate images in training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===========================================================')\n",
    "print('Validating training files ')\n",
    "print('===========================================================')\n",
    "for img_idx in range(0, df_train.shape[0]):\n",
    "    img_name = df_train.iloc[image_idx,0]\n",
    "    try:\n",
    "        img = cv2.imread(img_name)\n",
    "    except:\n",
    "        print('Corrupted file ', img_name)\n",
    "        \n",
    "print('===========================================================')\n",
    "print('Validating validation files ')\n",
    "print('===========================================================')   \n",
    "for img_idx in range(0, df_val.shape[0]):\n",
    "    img_name = df_val.iloc[image_idx,0]\n",
    "    img = cv2.imread(img_name)\n",
    "    try:\n",
    "        img = cv2.imread(img_name)\n",
    "    except:\n",
    "        print('Corrupted file ', img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = np.random.randint(0,df_val.shape[0])\n",
    "print(image_idx)\n",
    "img_name = df_val.iloc[image_idx,0]\n",
    "img = cv2.imread(img_name)\n",
    "xmin = df_val.iloc[image_idx,1]\n",
    "xmax = df_val.iloc[image_idx,2]\n",
    "ymin = df_val.iloc[image_idx,3]\n",
    "ymax = df_val.iloc[image_idx,4]\n",
    "\n",
    "cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),2)\n",
    "cv2.imshow('Features', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "img = df.iloc[0,0]\n",
    "img = imread(img)\n",
    "xmin = df.iloc[0,1]\n",
    "xmax = df.iloc[0,2]\n",
    "ymin = df.iloc[0,3]\n",
    "ymax = df.iloc[0,4]\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(255,255,255),2)\n",
    "cv2.imshow('Features', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating artificial images:\n",
    "* Translation\n",
    "* Rotation\n",
    "* Scaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([min_i, max_i]))\n",
    "print(np.array([min_j, max_j]))\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transformation(back_image, min_max_i, min_max_j):\n",
    "    min_i, max_i = min_max_i\n",
    "    min_j, max_j = min_max_j\n",
    "    rectangle_points = np.array([[min_i, min_i, max_i, max_i],\n",
    "                                 [min_j, max_j, min_j, max_j]])\n",
    "    rectangle_points = np.vstack((rectangle_points, [1., 1., 1., 1.]))\n",
    "\n",
    "    random_rot_angle = np.random.uniform(0, 2*np.pi)\n",
    "    random_rot_matrix = np.array([[np.cos(random_rot_angle), -np.sin(random_rot_angle)],\n",
    "                                  [np.sin(random_rot_angle), np.cos(random_rot_angle)]])\n",
    "    random_translation_x = np.random.uniform(-min_i, back_image.shape[1]-max_i)\n",
    "    random_translation_y = np.random.uniform(-min_j, back_image.shape[0]-max_j)\n",
    "    translation_vector = np.array([[random_translation_x], [random_translation_y]])\n",
    "\n",
    "    t = np.hstack((random_rot_matrix, translation_vector))\n",
    "    t = np.vstack((t, np.array([0., 0., 1.])))\n",
    "\n",
    "    transformed_bb = t.dot(rectangle_points)\n",
    "    transformed_bb = np.array(transformed_bb, dtype=int)\n",
    "\n",
    "    use_transformation = True\n",
    "    for point in transformed_bb.T:\n",
    "        if point[0] < 0 or point[0] > back_image.shape[0] or \\\n",
    "           point[1] < 0 or point[1] > back_image.shape[1]:\n",
    "            use_transformation = False\n",
    "            break\n",
    "    return t, use_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_transformation = False\n",
    "t = None\n",
    "while not use_transformation:\n",
    "    t, use_transformation = generate_transformation(back_image,\n",
    "                                                    (min_i, max_i),\n",
    "                                                    (min_j, max_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_coords = np.vstack((nonzero_rows[np.newaxis],\n",
    "                        nonzero_cols[np.newaxis],\n",
    "                        np.ones(len(nonzero_rows), dtype=int)))\n",
    "\n",
    "# t = np.array([[np.cos(np.pi/4.), -np.sin(np.pi/4.), 200.], [np.sin(np.pi/4.), np.cos(np.pi/4.), 500.], [0., 0., 1.]])\n",
    "transformed_obj_coords = t.dot(obj_coords)\n",
    "transformed_obj_coords = np.array(transformed_obj_coords, dtype=int)\n",
    "\n",
    "for i, point in enumerate(transformed_obj_coords.T):\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "\n",
    "    back_image[x, y] = img[obj_coords[0, i], obj_coords[1, i]]\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.imshow(back_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
